{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/gpfs/data/home/i.zakazov/domain_adaptation_mri/damri/model/\")\n",
    "from unet import *\n",
    "from unet3D import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet2D(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet2D(\n",
       "  (init_path): Sequential(\n",
       "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): ReLU()\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (shortcut0): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down1): Sequential(\n",
       "    (0): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(8, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (shortcut1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down2): Sequential(\n",
       "    (0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (shortcut2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (down3): Sequential(\n",
       "    (0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (1): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (2): ReLU()\n",
       "    (3): Identity()\n",
       "    (4): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Identity()\n",
       "  )\n",
       "  (up3): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up2): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (up1): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): ConvTranspose2d(16, 8, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "    (5): ReLU()\n",
       "    (6): Identity()\n",
       "  )\n",
       "  (out_path): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (conv_path): Sequential(\n",
       "        (0): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): PreActivationND(\n",
       "          (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (layer): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): PreActivationND(\n",
       "      (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_path.0.weight\n",
      "init_path.2.conv_path.0.bn.weight\n",
      "init_path.2.conv_path.0.bn.bias\n",
      "init_path.2.conv_path.0.layer.weight\n",
      "init_path.2.conv_path.1.bn.weight\n",
      "init_path.2.conv_path.1.bn.bias\n",
      "init_path.2.conv_path.1.layer.weight\n",
      "init_path.3.conv_path.0.bn.weight\n",
      "init_path.3.conv_path.0.bn.bias\n",
      "init_path.3.conv_path.0.layer.weight\n",
      "init_path.3.conv_path.1.bn.weight\n",
      "init_path.3.conv_path.1.bn.bias\n",
      "init_path.3.conv_path.1.layer.weight\n",
      "init_path.4.conv_path.0.bn.weight\n",
      "init_path.4.conv_path.0.bn.bias\n",
      "init_path.4.conv_path.0.layer.weight\n",
      "init_path.4.conv_path.1.bn.weight\n",
      "init_path.4.conv_path.1.bn.bias\n",
      "init_path.4.conv_path.1.layer.weight\n",
      "shortcut0.weight\n",
      "shortcut0.bias\n",
      "down1.0.weight\n",
      "down1.0.bias\n",
      "down1.1.weight\n",
      "down1.4.conv_path.0.bn.weight\n",
      "down1.4.conv_path.0.bn.bias\n",
      "down1.4.conv_path.0.layer.weight\n",
      "down1.4.conv_path.1.bn.weight\n",
      "down1.4.conv_path.1.bn.bias\n",
      "down1.4.conv_path.1.layer.weight\n",
      "down1.5.conv_path.0.bn.weight\n",
      "down1.5.conv_path.0.bn.bias\n",
      "down1.5.conv_path.0.layer.weight\n",
      "down1.5.conv_path.1.bn.weight\n",
      "down1.5.conv_path.1.bn.bias\n",
      "down1.5.conv_path.1.layer.weight\n",
      "down1.6.conv_path.0.bn.weight\n",
      "down1.6.conv_path.0.bn.bias\n",
      "down1.6.conv_path.0.layer.weight\n",
      "down1.6.conv_path.1.bn.weight\n",
      "down1.6.conv_path.1.bn.bias\n",
      "down1.6.conv_path.1.layer.weight\n",
      "shortcut1.weight\n",
      "shortcut1.bias\n",
      "down2.0.weight\n",
      "down2.0.bias\n",
      "down2.1.weight\n",
      "down2.4.conv_path.0.bn.weight\n",
      "down2.4.conv_path.0.bn.bias\n",
      "down2.4.conv_path.0.layer.weight\n",
      "down2.4.conv_path.1.bn.weight\n",
      "down2.4.conv_path.1.bn.bias\n",
      "down2.4.conv_path.1.layer.weight\n",
      "down2.5.conv_path.0.bn.weight\n",
      "down2.5.conv_path.0.bn.bias\n",
      "down2.5.conv_path.0.layer.weight\n",
      "down2.5.conv_path.1.bn.weight\n",
      "down2.5.conv_path.1.bn.bias\n",
      "down2.5.conv_path.1.layer.weight\n",
      "down2.6.conv_path.0.bn.weight\n",
      "down2.6.conv_path.0.bn.bias\n",
      "down2.6.conv_path.0.layer.weight\n",
      "down2.6.conv_path.1.bn.weight\n",
      "down2.6.conv_path.1.bn.bias\n",
      "down2.6.conv_path.1.layer.weight\n",
      "shortcut2.weight\n",
      "shortcut2.bias\n",
      "down3.0.weight\n",
      "down3.0.bias\n",
      "down3.1.weight\n",
      "down3.4.conv_path.0.bn.weight\n",
      "down3.4.conv_path.0.bn.bias\n",
      "down3.4.conv_path.0.layer.weight\n",
      "down3.4.conv_path.1.bn.weight\n",
      "down3.4.conv_path.1.bn.bias\n",
      "down3.4.conv_path.1.layer.weight\n",
      "down3.5.conv_path.0.bn.weight\n",
      "down3.5.conv_path.0.bn.bias\n",
      "down3.5.conv_path.0.layer.weight\n",
      "down3.5.conv_path.1.bn.weight\n",
      "down3.5.conv_path.1.bn.bias\n",
      "down3.5.conv_path.1.layer.weight\n",
      "down3.6.conv_path.0.bn.weight\n",
      "down3.6.conv_path.0.bn.bias\n",
      "down3.6.conv_path.0.layer.weight\n",
      "down3.6.conv_path.1.bn.weight\n",
      "down3.6.conv_path.1.bn.bias\n",
      "down3.6.conv_path.1.layer.weight\n",
      "up3.0.conv_path.0.bn.weight\n",
      "up3.0.conv_path.0.bn.bias\n",
      "up3.0.conv_path.0.layer.weight\n",
      "up3.0.conv_path.1.bn.weight\n",
      "up3.0.conv_path.1.bn.bias\n",
      "up3.0.conv_path.1.layer.weight\n",
      "up3.1.conv_path.0.bn.weight\n",
      "up3.1.conv_path.0.bn.bias\n",
      "up3.1.conv_path.0.layer.weight\n",
      "up3.1.conv_path.1.bn.weight\n",
      "up3.1.conv_path.1.bn.bias\n",
      "up3.1.conv_path.1.layer.weight\n",
      "up3.2.conv_path.0.bn.weight\n",
      "up3.2.conv_path.0.bn.bias\n",
      "up3.2.conv_path.0.layer.weight\n",
      "up3.2.conv_path.1.bn.weight\n",
      "up3.2.conv_path.1.bn.bias\n",
      "up3.2.conv_path.1.layer.weight\n",
      "up3.3.weight\n",
      "up3.3.bias\n",
      "up3.4.weight\n",
      "up2.0.conv_path.0.bn.weight\n",
      "up2.0.conv_path.0.bn.bias\n",
      "up2.0.conv_path.0.layer.weight\n",
      "up2.0.conv_path.1.bn.weight\n",
      "up2.0.conv_path.1.bn.bias\n",
      "up2.0.conv_path.1.layer.weight\n",
      "up2.1.conv_path.0.bn.weight\n",
      "up2.1.conv_path.0.bn.bias\n",
      "up2.1.conv_path.0.layer.weight\n",
      "up2.1.conv_path.1.bn.weight\n",
      "up2.1.conv_path.1.bn.bias\n",
      "up2.1.conv_path.1.layer.weight\n",
      "up2.2.conv_path.0.bn.weight\n",
      "up2.2.conv_path.0.bn.bias\n",
      "up2.2.conv_path.0.layer.weight\n",
      "up2.2.conv_path.1.bn.weight\n",
      "up2.2.conv_path.1.bn.bias\n",
      "up2.2.conv_path.1.layer.weight\n",
      "up2.3.weight\n",
      "up2.3.bias\n",
      "up2.4.weight\n",
      "up1.0.conv_path.0.bn.weight\n",
      "up1.0.conv_path.0.bn.bias\n",
      "up1.0.conv_path.0.layer.weight\n",
      "up1.0.conv_path.1.bn.weight\n",
      "up1.0.conv_path.1.bn.bias\n",
      "up1.0.conv_path.1.layer.weight\n",
      "up1.1.conv_path.0.bn.weight\n",
      "up1.1.conv_path.0.bn.bias\n",
      "up1.1.conv_path.0.layer.weight\n",
      "up1.1.conv_path.1.bn.weight\n",
      "up1.1.conv_path.1.bn.bias\n",
      "up1.1.conv_path.1.layer.weight\n",
      "up1.2.conv_path.0.bn.weight\n",
      "up1.2.conv_path.0.bn.bias\n",
      "up1.2.conv_path.0.layer.weight\n",
      "up1.2.conv_path.1.bn.weight\n",
      "up1.2.conv_path.1.bn.bias\n",
      "up1.2.conv_path.1.layer.weight\n",
      "up1.3.weight\n",
      "up1.3.bias\n",
      "up1.4.weight\n",
      "out_path.0.conv_path.0.bn.weight\n",
      "out_path.0.conv_path.0.bn.bias\n",
      "out_path.0.conv_path.0.layer.weight\n",
      "out_path.0.conv_path.1.bn.weight\n",
      "out_path.0.conv_path.1.bn.bias\n",
      "out_path.0.conv_path.1.layer.weight\n",
      "out_path.1.bn.weight\n",
      "out_path.1.bn.bias\n",
      "out_path.1.layer.weight\n",
      "out_path.1.layer.bias\n",
      "out_path.2.weight\n",
      "out_path.2.bias\n"
     ]
    }
   ],
   "source": [
    "for p in net.named_parameters():\n",
    "    print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inconv.conv1.weight\n",
      "inconv.conv2.bn.weight\n",
      "inconv.conv2.bn.bias\n",
      "inconv.conv2.layer.weight\n",
      "inconv.conv2.layer.bias\n",
      "down1.pool_conv.1.bn.weight\n",
      "down1.pool_conv.1.bn.bias\n",
      "down1.pool_conv.1.layer.weight\n",
      "down1.pool_conv.2.bn.weight\n",
      "down1.pool_conv.2.bn.bias\n",
      "down1.pool_conv.2.layer.weight\n",
      "down1.pool_conv.2.layer.bias\n",
      "down2.pool_conv.1.bn.weight\n",
      "down2.pool_conv.1.bn.bias\n",
      "down2.pool_conv.1.layer.weight\n",
      "down2.pool_conv.2.bn.weight\n",
      "down2.pool_conv.2.bn.bias\n",
      "down2.pool_conv.2.layer.weight\n",
      "down2.pool_conv.2.layer.bias\n",
      "down3.pool_conv.1.bn.weight\n",
      "down3.pool_conv.1.bn.bias\n",
      "down3.pool_conv.1.layer.weight\n",
      "down3.pool_conv.2.bn.weight\n",
      "down3.pool_conv.2.bn.bias\n",
      "down3.pool_conv.2.layer.weight\n",
      "down3.pool_conv.2.layer.bias\n",
      "up1.up.weight\n",
      "up1.up.bias\n",
      "up1.conv1.bn.weight\n",
      "up1.conv1.bn.bias\n",
      "up1.conv1.layer.weight\n",
      "up1.conv2.bn.weight\n",
      "up1.conv2.bn.bias\n",
      "up1.conv2.layer.weight\n",
      "up1.conv2.layer.bias\n",
      "up2.up.weight\n",
      "up2.up.bias\n",
      "up2.conv1.bn.weight\n",
      "up2.conv1.bn.bias\n",
      "up2.conv1.layer.weight\n",
      "up2.conv2.bn.weight\n",
      "up2.conv2.bn.bias\n",
      "up2.conv2.layer.weight\n",
      "up2.conv2.layer.bias\n",
      "up3.up.weight\n",
      "up3.up.bias\n",
      "up3.conv1.bn.weight\n",
      "up3.conv1.bn.bias\n",
      "up3.conv1.layer.weight\n",
      "up3.conv2.bn.weight\n",
      "up3.conv2.bn.bias\n",
      "up3.conv2.layer.weight\n",
      "up3.conv2.layer.bias\n",
      "outconv.conv.bn.weight\n",
      "outconv.conv.bn.bias\n",
      "outconv.conv.layer.weight\n",
      "outconv.bn.weight\n",
      "outconv.bn.bias\n"
     ]
    }
   ],
   "source": [
    "for p in net.named_parameters():\n",
    "    print(p[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, num_layers):\n",
    "    for i, params in enumerate(model.parameters()):\n",
    "        if i==num_layers:\n",
    "            break\n",
    "        params.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_model(net,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of UNet3D(\n",
       "  (inconv): InitConv(\n",
       "    (conv1): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (conv2): PreActivationND(\n",
       "      (bn): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (down1): DownBlock(\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): PreActivationND(\n",
       "        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (2): PreActivationND(\n",
       "        (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): DownBlock(\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): PreActivationND(\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (2): PreActivationND(\n",
       "        (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): DownBlock(\n",
       "    (pool_conv): Sequential(\n",
       "      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): PreActivationND(\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (2): PreActivationND(\n",
       "        (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (activation): ReLU()\n",
       "        (layer): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): UpBlock(\n",
       "    (up): ConvTranspose3d(512, 512, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (conv1): PreActivationND(\n",
       "      (bn): BatchNorm3d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(768, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): PreActivationND(\n",
       "      (bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (up2): UpBlock(\n",
       "    (up): ConvTranspose3d(256, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (conv1): PreActivationND(\n",
       "      (bn): BatchNorm3d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(384, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): PreActivationND(\n",
       "      (bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (up3): UpBlock(\n",
       "    (up): ConvTranspose3d(128, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    (conv1): PreActivationND(\n",
       "      (bn): BatchNorm3d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(192, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (conv2): PreActivationND(\n",
       "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (outconv): OutConv(\n",
       "    (conv): PreActivationND(\n",
       "      (bn): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (activation): ReLU()\n",
       "      (layer): Conv3d(64, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (bn): BatchNorm3d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}